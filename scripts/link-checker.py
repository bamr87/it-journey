#!/usr/bin/env python3
"""
IT-Journey Link Health Guardian - Comprehensive Link Checker
A unified script for link checking, analysis, and AI-powered insights
"""

import argparse
import json
import os
import re
import subprocess
import sys
import time
from collections import defaultdict
from datetime import datetime
from pathlib import Path

import requests


class LinkHealthGuardian:
    def __init__(self, config):
        self.config = config
        self.output_dir = config.get('output_dir', 'link-check-results')
        self.results = {}
        self.analysis = {}
        self.ai_analysis = {}
        
        # Ensure output directory exists
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)
        
        # Initialize logging
        self.setup_logging()
    
    def setup_logging(self):
        """Setup colored logging for better output visibility."""
        self.colors = {
            'INFO': '\033[0;34m',
            'SUCCESS': '\033[0;32m',
            'WARNING': '\033[1;33m',
            'ERROR': '\033[0;31m',
            'NC': '\033[0m'  # No Color
        }
    
    def log(self, level, message):
        """Log a message with color coding."""
        color = self.colors.get(level, '')
        nc = self.colors['NC']
        print(f"{color}[{level}]{nc} {message}")
    
    def install_dependencies(self):
        """Install required dependencies for link checking."""
        self.log('INFO', 'Installing link checking dependencies...')
        
        try:
            # Check if lychee is already installed
            result = subprocess.run(['lychee', '--version'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                self.log('SUCCESS', f'Lychee already installed: {result.stdout.strip()}')
                return True
        except FileNotFoundError:
            pass
        
        # Install lychee
        self.log('INFO', 'Installing Lychee link checker...')
        try:
            # Download and install lychee
            install_cmd = [
                'curl', '-sSfL',
                'https://github.com/lycheeverse/lychee/releases/latest/download/lychee-x86_64-unknown-linux-gnu.tar.gz',
                '|', 'tar', '-xz', '-C', '/tmp'
            ]
            subprocess.run(' '.join(install_cmd), shell=True, check=True)
            subprocess.run(['sudo', 'mv', '/tmp/lychee', '/usr/local/bin/'], check=True)
            subprocess.run(['sudo', 'chmod', '+x', '/usr/local/bin/lychee'], check=True)
            
            # Verify installation
            result = subprocess.run(['lychee', '--version'], 
                                  capture_output=True, text=True, check=True)
            self.log('SUCCESS', f'Lychee installed successfully: {result.stdout.strip()}')
            return True
            
        except subprocess.CalledProcessError as e:
            self.log('ERROR', f'Failed to install Lychee: {e}')
            return False
    
    def determine_scope_files(self, scope):
        """Determine which files to check based on scope."""
        scope_mapping = {
            'website': '.',
            'all': '.',
            'docs': 'docs/',
            'posts': 'pages/_posts/',
            'quests': 'pages/_quests/',
            'internal': '.',
            'external': '.'
        }
        
        base_path = scope_mapping.get(scope, '.')
        
        # Find all markdown files in the specified path
        files = []
        for ext in ['*.md', '*.html', '*.htm']:
            if os.path.exists(base_path):
                files.extend(Path(base_path).rglob(ext))
        
        # Convert to strings and filter
        file_list = [str(f) for f in files]
        
        # For internal/external scope, we'll filter during analysis
        self.log('INFO', f'Scope "{scope}" includes {len(file_list)} files')
        return file_list if file_list else ['.']
    
    def run_link_check(self):
        """Execute the main link checking with Lychee."""
        self.log('INFO', 'Starting comprehensive link health check...')
        
        scope = self.config.get('scope', 'website')
        files = self.determine_scope_files(scope)
        
        # Build lychee command
        cmd = [
            'lychee',
            '--format', 'json',
            '--output', os.path.join(self.output_dir, 'lychee_results.json'),
            '--timeout', str(self.config.get('timeout', 30)),
            '--max-retries', str(self.config.get('max_retries', 3)),
            '--user-agent', 'IT-Journey-LinkChecker/2.0 (GitHub Actions)',
            '--verbose',
            '--no-progress'
        ]
        
        # Add scope-specific options
        if scope == 'internal':
            cmd.extend(['--exclude-all-private'])
        elif scope == 'external':
            cmd.extend(['--include-verbatim', 'http'])
        
        # Add follow redirects option
        if self.config.get('follow_redirects', True):
            cmd.extend(['--remap'])
        
        # Add files to check
        cmd.extend(files)
        
        self.log('INFO', f'Running: {" ".join(cmd)}')
        
        try:
            # Run lychee and capture output
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=1800)  # 30 min timeout
            
            # Also generate markdown summary
            summary_cmd = cmd.copy()
            summary_cmd[summary_cmd.index('--format') + 1] = 'markdown'
            summary_cmd[summary_cmd.index('--output') + 1] = os.path.join(self.output_dir, 'summary.md')
            subprocess.run(summary_cmd, capture_output=True, text=True)
            
            self.log('SUCCESS', 'Link checking completed')
            return True
            
        except subprocess.TimeoutExpired:
            self.log('ERROR', 'Link checking timed out after 30 minutes')
            return False
        except subprocess.CalledProcessError as e:
            self.log('WARNING', f'Link checking completed with some failures: {e}')
            return True  # Continue with analysis even if some links failed
        except Exception as e:
            self.log('ERROR', f'Link checking failed: {e}')
            return False
    
    def parse_lychee_results(self):
        """Parse Lychee JSON results and extract statistics."""
        results_file = os.path.join(self.output_dir, 'lychee_results.json')
        
        if not os.path.exists(results_file):
            self.log('WARNING', 'No Lychee results file found')
            return False
        
        try:
            with open(results_file, 'r') as f:
                data = json.load(f)
            
            # Extract statistics
            total = data.get('total', 0)
            successful = data.get('successful', 0)
            errors = data.get('errors', 0)
            success_rate = (successful / total * 100) if total > 0 else 100
            
            # Store basic stats
            self.results = {
                'total_links': total,
                'successful_links': successful,
                'broken_links': errors,
                'success_rate': round(success_rate, 1),
                'raw_data': data
            }
            
            # Save statistics for GitHub Actions
            stats_file = os.path.join(self.output_dir, 'statistics.env')
            with open(stats_file, 'w') as f:
                f.write(f"TOTAL_COUNT={total}\n")
                f.write(f"BROKEN_COUNT={errors}\n")
                f.write(f"SUCCESS_RATE={success_rate:.1f}\n")
            
            self.log('SUCCESS', f'Parsed results: {total} total, {errors} broken, {success_rate:.1f}% success')
            return True
            
        except Exception as e:
            self.log('ERROR', f'Failed to parse Lychee results: {e}')
            return False
    
    def analyze_link_failures(self):
        """Analyze link failures and categorize them."""
        self.log('INFO', 'Analyzing link health patterns and trends...')
        
        if not self.results or not self.results.get('raw_data'):
            self.log('WARNING', 'No results data available for analysis')
            return False
        
        data = self.results['raw_data']
        
        # Initialize categories
        categories = {
            'broken_external': [],
            'broken_internal': [],
            'ssl_errors': [],
            'dns_errors': [],
            'timeouts': [],
            'rate_limited': [],
            'certificate_errors': [],
            'network_errors': [],
            'redirects': [],
            'unknown': []
        }
        
        # Process error map
        error_map = data.get('error_map', {})
        for file_path, errors in error_map.items():
            for error in errors:
                try:
                    url = error.get('url', '')
                    error_msg = str(error.get('status', '')).lower()
                    
                    # Create result object
                    result = {
                        'url': url,
                        'error': error_msg,
                        'file': file_path,
                        'status': 'Failed'
                    }
                    
                    # Categorize by error type
                    if any(term in error_msg for term in ['ssl', 'tls', 'certificate']):
                        if 'ssl' in error_msg or 'tls' in error_msg:
                            categories['ssl_errors'].append(result)
                        else:
                            categories['certificate_errors'].append(result)
                    elif any(term in error_msg for term in ['dns', 'resolve', 'hostname']):
                        categories['dns_errors'].append(result)
                    elif any(term in error_msg for term in ['timeout', 'timed out']):
                        categories['timeouts'].append(result)
                    elif any(term in error_msg for term in ['429', 'rate limit', 'too many']):
                        categories['rate_limited'].append(result)
                    elif any(term in error_msg for term in ['network', 'connection', 'refused']):
                        categories['network_errors'].append(result)
                    elif url.startswith('http'):
                        categories['broken_external'].append(result)
                    elif url.startswith('/') or not url.startswith('http'):
                        categories['broken_internal'].append(result)
                    else:
                        categories['unknown'].append(result)
                        
                except Exception as e:
                    self.log('WARNING', f'Error processing error entry: {e}')
                    continue
        
        # Analyze patterns
        patterns = self.identify_patterns(categories)
        
        # Store analysis
        self.analysis = {
            'categories': categories,
            'patterns': patterns,
            'summary': {
                'total_broken': sum(len(cat) for cat in categories.values()),
                'most_common_error': self.get_most_common_error(categories),
                'problematic_domains': self.get_problematic_domains(categories)
            },
            'analysis_timestamp': datetime.utcnow().isoformat() + 'Z'
        }
        
        # Generate detailed report
        self.generate_analysis_report()
        
        self.log('SUCCESS', f'Analysis completed: {len(patterns)} patterns identified')
        return True
    
    def identify_patterns(self, categories):
        """Identify patterns in link failures."""
        patterns = []
        
        # Domain failure analysis
        domain_failures = defaultdict(int)
        for category in ['broken_external', 'timeouts', 'rate_limited', 'ssl_errors', 'dns_errors']:
            for item in categories[category]:
                url = item.get('url', '')
                if url.startswith('http'):
                    try:
                        domain = url.split('/')[2]
                        domain_failures[domain] += 1
                    except:
                        pass
        
        if domain_failures:
            top_domains = sorted(domain_failures.items(), key=lambda x: x[1], reverse=True)[:3]
            patterns.append(f"Top failing domains: {', '.join([f'{d}({c})' for d, c in top_domains])}")
        
        # Category-specific patterns
        internal_count = len(categories['broken_internal'])
        if internal_count > 0:
            patterns.append(f"Found {internal_count} broken internal links - check Jekyll configuration")
        
        timeout_count = len(categories['timeouts'])
        if timeout_count > 5:
            patterns.append(f"High timeout rate ({timeout_count}) - network or slow sites")
        
        ssl_count = len(categories['ssl_errors'])
        if ssl_count > 0:
            patterns.append(f"SSL/TLS issues on {ssl_count} links - certificate problems")
        
        dns_count = len(categories['dns_errors'])
        if dns_count > 0:
            patterns.append(f"DNS resolution errors on {dns_count} links - domain issues")
        
        return patterns
    
    def get_most_common_error(self, categories):
        """Find the most common error category."""
        category_counts = {k: len(v) for k, v in categories.items()}
        if category_counts:
            return max(category_counts, key=category_counts.get)
        return 'none'
    
    def get_problematic_domains(self, categories):
        """Get list of problematic domains."""
        domains = set()
        for category in categories.values():
            for item in category:
                url = item.get('url', '')
                if url.startswith('http'):
                    try:
                        domain = url.split('/')[2]
                        domains.add(domain)
                    except:
                        pass
        return list(domains)[:5]  # Top 5
    
    def generate_analysis_report(self):
        """Generate detailed analysis report in markdown."""
        report_file = os.path.join(self.output_dir, 'detailed_analysis.md')
        
        with open(report_file, 'w') as f:
            f.write("# IT-Journey Link Health Analysis Report\n\n")
            f.write(f"**Analysis Date**: {self.analysis['analysis_timestamp']}\n")
            f.write(f"**Total Links**: {self.results['total_links']}\n")
            f.write(f"**Broken Links**: {self.results['broken_links']}\n")
            f.write(f"**Success Rate**: {self.results['success_rate']}%\n\n")
            
            if self.results['broken_links'] > 0:
                f.write("## Failure Categories\n\n")
                for category, items in self.analysis['categories'].items():
                    if items:
                        f.write(f"### {category.replace('_', ' ').title()}\n")
                        f.write(f"**Count**: {len(items)}\n\n")
                        for item in items[:5]:  # Show first 5
                            f.write(f"- **URL**: {item.get('url', 'Unknown')}\n")
                            f.write(f"  - **File**: {item.get('file', 'Unknown')}\n")
                            f.write(f"  - **Error**: {item.get('error', 'Unknown')}\n\n")
                        if len(items) > 5:
                            f.write(f"... and {len(items) - 5} more\n\n")
            
            if self.analysis['patterns']:
                f.write("## Identified Patterns\n\n")
                for pattern in self.analysis['patterns']:
                    f.write(f"- {pattern}\n")
                f.write("\n")
            
            f.write("## Recommendations\n\n")
            if self.results['broken_links'] == 0:
                f.write("🎉 Excellent! No broken links found.\n")
            else:
                f.write("### Priority Actions\n\n")
                f.write("1. **Fix Internal Links**: Address broken internal navigation first\n")
                f.write("2. **Update External Links**: Replace or remove broken external references\n")
                f.write("3. **Monitor SSL/DNS Issues**: Review certificate and domain problems\n")
                f.write("4. **Consider Rate Limiting**: Add problematic domains to ignore list\n")
        
        # Save analysis summary for GitHub Actions
        summary_file = os.path.join(self.output_dir, 'analysis_summary.env')
        with open(summary_file, 'w') as f:
            f.write(f"ANALYSIS_AVAILABLE=true\n")
            f.write(f"PATTERNS_COUNT={len(self.analysis['patterns'])}\n")
            f.write(f"MOST_COMMON_ERROR={self.analysis['summary']['most_common_error']}\n")
        
        self.log('SUCCESS', f'Analysis report generated: {report_file}')
    
    def run_ai_analysis(self):
        """Run AI-powered analysis if OpenAI API key is available."""
        if not self.config.get('ai_analysis', False):
            self.log('INFO', 'AI analysis disabled')
            return False
        
        api_key = os.environ.get('OPENAI_API_KEY')
        if not api_key:
            self.log('WARNING', 'OPENAI_API_KEY not found - skipping AI analysis')
            return self.generate_fallback_ai_analysis()
        
        self.log('INFO', 'Generating AI-powered insights...')
        
        try:
            # Prepare context for AI
            context = self.prepare_ai_context()
            
            # Make API request
            headers = {
                'Authorization': f'Bearer {api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': 'gpt-3.5-turbo',
                'messages': [
                    {
                        'role': 'user',
                        'content': self.build_ai_prompt(context)
                    }
                ],
                'max_tokens': 2000,
                'temperature': 0.3
            }
            
            response = requests.post(
                'https://api.openai.com/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                ai_content = result['choices'][0]['message']['content']
                
                # Save AI analysis
                self.save_ai_analysis(ai_content, True)
                self.log('SUCCESS', 'AI analysis completed successfully')
                return True
            else:
                self.log('ERROR', f'OpenAI API error: {response.status_code}')
                return self.generate_fallback_ai_analysis()
                
        except Exception as e:
            self.log('ERROR', f'AI analysis failed: {e}')
            return self.generate_fallback_ai_analysis()
    
    def prepare_ai_context(self):
        """Prepare context data for AI analysis."""
        return {
            'results': self.results,
            'analysis': self.analysis,
            'config': self.config,
            'repository': self.config.get('repository', 'IT-Journey'),
            'scope': self.config.get('scope', 'website')
        }
    
    def build_ai_prompt(self, context):
        """Build the AI analysis prompt."""
        results = context['results']
        analysis = context['analysis']
        
        prompt = f"""
Analyze this link health check for the IT-Journey educational repository:

## Summary Statistics
- Total links: {results['total_links']}
- Broken links: {results['broken_links']}
- Success rate: {results['success_rate']}%
- Scope: {context['scope']}

## Failure Categories
"""
        
        for category, items in analysis['categories'].items():
            if items:
                prompt += f"- {category.replace('_', ' ').title()}: {len(items)} links\n"
        
        if analysis['patterns']:
            prompt += f"\n## Identified Patterns\n"
            for pattern in analysis['patterns']:
                prompt += f"- {pattern}\n"
        
        prompt += """

## Analysis Request
Please provide a comprehensive analysis including:

1. **Root Cause Analysis**: Most likely causes for these link failures
2. **Educational Impact**: How these issues affect learning experience
3. **Priority Recommendations**: Specific actions ranked by importance
4. **Prevention Strategies**: How to avoid similar issues
5. **Technical Solutions**: Jekyll/GitHub Pages specific fixes

Focus on actionable insights for maintaining an educational platform.
Format your response in clear markdown sections.
"""
        
        return prompt
    
    def generate_fallback_ai_analysis(self):
        """Generate fallback analysis when AI is not available."""
        self.log('INFO', 'Generating fallback analysis...')
        
        results = self.results
        analysis = self.analysis
        
        content = f"""# AI-Powered Link Analysis (Fallback Mode)

## Executive Summary
Analyzed {results['total_links']} links with {results['broken_links']} failures ({results['success_rate']}% success rate).

## Root Cause Analysis
Based on failure patterns, the most common issues are:
- **{analysis['summary']['most_common_error'].replace('_', ' ').title()}**: Primary failure category
- **External Dependencies**: Third-party sites may have availability issues
- **Configuration Issues**: Internal links may reflect Jekyll setup problems

## Educational Impact Assessment
Link failures impact the learning experience by:
- Disrupting learning flow when students encounter broken references
- Reducing credibility of educational content
- Creating frustration during self-paced learning

## Priority Recommendations
1. **Fix Internal Links**: Highest priority - affects site navigation
2. **Review External Sources**: Update or replace unreliable external references
3. **Implement Monitoring**: Regular automated checks to catch issues early
4. **Documentation Updates**: Keep resource links current and valid

## Prevention Strategies
- Regular link health monitoring (weekly checks)
- Use archived links for critical external resources
- Implement redirect management for moved content
- Test links before publishing new content

*Note: Enhanced AI analysis requires OPENAI_API_KEY configuration.*
"""
        
        self.save_ai_analysis(content, False)
        return True
    
    def save_ai_analysis(self, content, is_ai_powered):
        """Save AI analysis results."""
        ai_file = os.path.join(self.output_dir, 'ai_analysis.md')
        with open(ai_file, 'w') as f:
            f.write(content)
        
        # Save summary for GitHub Actions
        ai_summary_file = os.path.join(self.output_dir, 'ai_analysis_summary.env')
        with open(ai_summary_file, 'w') as f:
            f.write(f"AI_ANALYSIS_AVAILABLE=true\n")
            f.write(f"AI_POWERED={str(is_ai_powered).lower()}\n")
            f.write(f"AI_ANALYSIS_TYPE={'openai' if is_ai_powered else 'fallback'}\n")
        
        self.log('SUCCESS', f'AI analysis saved: {ai_file}')
    
    def create_github_issue(self):
        """Create GitHub issue with comprehensive results."""
        if not self.config.get('create_issue', False):
            self.log('INFO', 'GitHub issue creation disabled')
            return False
        
        self.log('INFO', 'Creating GitHub issue with comprehensive results...')
        
        # Generate issue content
        issue_title = self.generate_issue_title()
        issue_body = self.generate_issue_body()
        
        # Save issue body for manual creation if needed
        issue_file = os.path.join(self.output_dir, 'issue_body.md')
        with open(issue_file, 'w') as f:
            f.write(issue_body)
        
        # Try to create issue using GitHub CLI
        try:
            cmd = [
                'gh', 'issue', 'create',
                '--title', issue_title,
                '--body-file', issue_file,
                '--label', self.get_issue_labels(),
                '--assignee', '@me'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            issue_url = result.stdout.strip()
            
            # Save issue URL
            with open(os.path.join(self.output_dir, 'issue_url.txt'), 'w') as f:
                f.write(issue_url)
            
            self.log('SUCCESS', f'GitHub issue created: {issue_url}')
            return True
            
        except subprocess.CalledProcessError as e:
            self.log('ERROR', f'Failed to create GitHub issue: {e}')
            self.log('INFO', f'Issue body saved to: {issue_file}')
            return False
        except FileNotFoundError:
            self.log('ERROR', 'GitHub CLI not found - issue body saved for manual creation')
            self.log('INFO', f'Issue body saved to: {issue_file}')
            return False
    
    def generate_issue_title(self):
        """Generate appropriate issue title."""
        broken_count = self.results['broken_links']
        date_str = datetime.now().strftime('%Y-%m-%d')
        
        if broken_count == 0:
            return f"🔗 Link Health Report - All Links Healthy ({date_str})"
        else:
            return f"🔗 Link Health Report - {broken_count} broken links found ({date_str})"
    
    def generate_issue_body(self):
        """Generate comprehensive issue body."""
        results = self.results
        timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')
        
        body = f"""# 🔗 IT-Journey Link Health Report

**Scan Date**: {timestamp}
**Repository**: {self.config.get('repository', 'IT-Journey')}
**Scope**: {self.config.get('scope', 'website')}
**Guardian Version**: 2.0.0

## 📊 Summary Statistics

- **Total links checked**: {results['total_links']}
- **Working links**: {results['successful_links']}
- **Broken links**: {results['broken_links']}
- **Success rate**: {results['success_rate']}%

"""
        
        if results['broken_links'] == 0:
            body += """## ✅ Status: Excellent

🎉 **All links are healthy!** Your IT-Journey site maintains perfect link integrity.

This demonstrates excellent maintenance practices and ensures a seamless learning experience for all users.
"""
        else:
            # Add status based on success rate
            success_rate = results['success_rate']
            if success_rate >= 95:
                status = "⚠️ Good (minor issues)"
            elif success_rate >= 90:
                status = "🟡 Fair (some issues)"
            elif success_rate >= 80:
                status = "🟠 Poor (multiple issues)"
            else:
                status = "🔴 Critical (major issues)"
            
            body += f"""## {status.split()[0]} Status: {status.split()[1:]}

**{results['broken_links']} broken links** were detected that may impact the learning experience.
"""
        
        # Add detailed analysis if available
        analysis_file = os.path.join(self.output_dir, 'detailed_analysis.md')
        if os.path.exists(analysis_file):
            body += "\n## 🔍 Detailed Analysis\n\n"
            with open(analysis_file, 'r') as f:
                body += f.read()
            body += "\n"
        
        # Add AI analysis if available
        ai_file = os.path.join(self.output_dir, 'ai_analysis.md')
        if os.path.exists(ai_file):
            body += "\n## 🤖 AI-Powered Insights\n\n"
            with open(ai_file, 'r') as f:
                body += f.read()
            body += "\n"
        
        # Add action items if there are broken links
        if results['broken_links'] > 0:
            body += """## 🛠️ Recommended Actions

### Immediate Actions
1. **Review Broken Links**: Check the detailed results above for specific URLs and errors
2. **Fix Internal Links**: Priority should be given to broken internal navigation
3. **Update External References**: Replace or remove broken external links
4. **Test Changes**: Verify fixes don't introduce new issues

### Preventive Measures
1. **Regular Monitoring**: Schedule weekly link health checks
2. **Content Guidelines**: Establish link validation procedures for new content
3. **Automated Testing**: Integrate link checking into CI/CD pipeline
4. **Documentation**: Update link maintenance procedures
"""
        
        body += f"""## 🔄 Re-running This Check

You can manually trigger another link check by:
1. Going to the [Actions tab](../../actions/workflows/link-health-guardian.yml)
2. Clicking "Run workflow"
3. Selecting your preferred scope and options

---

**Technical Details:**
- **Workflow**: Link Health Guardian v2.0
- **Scope**: {self.config.get('scope', 'website')}
- **Analysis Level**: {self.config.get('analysis_level', 'comprehensive')}
- **AI Analysis**: {'Enabled' if self.config.get('ai_analysis') else 'Disabled'}

*This issue was created automatically by the IT-Journey Link Health Guardian. 🤖*
"""
        
        return body
    
    def get_issue_labels(self):
        """Get appropriate labels for the GitHub issue."""
        labels = ['automated', 'link-checker', 'maintenance']
        
        if self.results['broken_links'] > 0:
            labels.append('bug')
        
        if os.path.exists(os.path.join(self.output_dir, 'ai_analysis.md')):
            labels.append('ai-analysis')
        
        return ','.join(labels)
    
    def run_full_workflow(self):
        """Run the complete link checking workflow."""
        self.log('INFO', 'IT-Journey Link Health Guardian v2.0')
        self.log('INFO', '=' * 50)
        
        # Step 1: Install dependencies (only on systems that need it)
        if not self.config.get('skip_install', False):
            if not self.install_dependencies():
                self.log('ERROR', 'Failed to install dependencies')
                return False
        
        # Step 2: Run link checking
        if self.config.get('analysis_level') != 'ai-only':
            if not self.run_link_check():
                self.log('ERROR', 'Link checking failed')
                return False
            
            if not self.parse_lychee_results():
                self.log('ERROR', 'Failed to parse link check results')
                return False
        else:
            self.log('INFO', 'Skipping link checking (AI-only mode)')
        
        # Step 3: Analyze results (if analysis level requires it)
        analysis_level = self.config.get('analysis_level', 'comprehensive')
        if analysis_level in ['standard', 'comprehensive']:
            if not self.analyze_link_failures():
                self.log('WARNING', 'Analysis failed but continuing...')
        
        # Step 4: Run AI analysis (if enabled and level requires it)
        if analysis_level in ['comprehensive', 'ai-only']:
            if not self.run_ai_analysis():
                self.log('WARNING', 'AI analysis failed but continuing...')
        
        # Step 5: Create GitHub issue (if enabled)
        if not self.create_github_issue():
            self.log('WARNING', 'GitHub issue creation failed but continuing...')
        
        # Final summary
        self.log('INFO', 'Workflow Summary:')
        if hasattr(self, 'results') and self.results:
            self.log('INFO', f'  Total links: {self.results.get("total_links", 0)}')
            self.log('INFO', f'  Broken links: {self.results.get("broken_links", 0)}')
            self.log('INFO', f'  Success rate: {self.results.get("success_rate", 0)}%')
        
        self.log('SUCCESS', 'Link Health Guardian workflow completed!')
        
        # Return appropriate exit code
        if hasattr(self, 'results') and self.results.get('broken_links', 0) > 0:
            return False  # Indicate broken links found
        return True


def main():
    """Main function with argument parsing."""
    parser = argparse.ArgumentParser(
        description='IT-Journey Link Health Guardian v2.0',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    python3 link-checker.py --scope website --analysis-level comprehensive
    python3 link-checker.py --scope docs --analysis-level basic --no-ai
    python3 link-checker.py --scope posts --create-issue --timeout 60
    python3 link-checker.py --analysis-level ai-only --ai-analysis
        """
    )
    
    # Core options
    parser.add_argument('--scope', default='website',
                       choices=['website', 'internal', 'external', 'docs', 'posts', 'quests', 'all'],
                       help='Scope of link checking')
    
    parser.add_argument('--analysis-level', default='comprehensive',
                       choices=['basic', 'standard', 'comprehensive', 'ai-only'],
                       help='Level of analysis to perform')
    
    parser.add_argument('--output-dir', default='link-check-results',
                       help='Output directory for results')
    
    # Link checking options
    parser.add_argument('--timeout', type=int, default=30,
                       help='Request timeout in seconds')
    
    parser.add_argument('--max-retries', type=int, default=3,
                       help='Maximum retry attempts for failed links')
    
    parser.add_argument('--follow-redirects', action='store_true', default=True,
                       help='Follow HTTP redirects')
    
    parser.add_argument('--no-follow-redirects', dest='follow_redirects', action='store_false',
                       help='Do not follow HTTP redirects')
    
    # Analysis options
    parser.add_argument('--ai-analysis', action='store_true', default=True,
                       help='Enable AI-powered analysis')
    
    parser.add_argument('--no-ai', dest='ai_analysis', action='store_false',
                       help='Disable AI-powered analysis')
    
    # GitHub integration
    parser.add_argument('--create-issue', action='store_true', default=False,
                       help='Create GitHub issue with results')
    
    parser.add_argument('--repository',
                       help='Repository in format owner/repo')
    
    # System options
    parser.add_argument('--skip-install', action='store_true',
                       help='Skip dependency installation')
    
    args = parser.parse_args()
    
    # Convert args to config dict
    config = {
        'scope': args.scope,
        'analysis_level': args.analysis_level,
        'output_dir': args.output_dir,
        'timeout': args.timeout,
        'max_retries': args.max_retries,
        'follow_redirects': args.follow_redirects,
        'ai_analysis': args.ai_analysis,
        'create_issue': args.create_issue,
        'repository': args.repository,
        'skip_install': args.skip_install
    }
    
    # Run the workflow
    guardian = LinkHealthGuardian(config)
    success = guardian.run_full_workflow()
    
    # Exit with appropriate code
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()