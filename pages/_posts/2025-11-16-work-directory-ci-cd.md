---
title: "The work/ Directory: CI/CD Integration Best Practices"
description: Master the work/ directory pattern for fast, isolated, cacheable, and disposable CI/CD workspaces that maximize build speed and minimize flakiness across any pipeline.
date: 2025-11-16T03:00:00.000Z
preview: /images/post-preview-work-cicd.png
tags:
    - ci-cd
    - devops
    - build-systems
    - automation
    - best-practices
    - performance-optimization
categories:
    - Posts
    - DevOps
    - Tutorials
sub-title: Transform your CI/CD with ephemeral, cacheable, high-speed workspaces
excerpt: The work/ directory pattern provides a structured, performance-optimized approach to CI/CD builds‚Äîseparating persistent caches from disposable artifacts while maintaining reproducibility and speed.
snippet: In CI/CD, work/ is your high-speed conveyor belt‚Äîfeed it materials, cache tools, produce goods, ship reports, wipe clean.
author: IT-Journey Team
layout: journals
section: DevOps
keywords:
    primary:
        - work-directory
        - ci-cd-optimization
    secondary:
        - build-caching
        - pipeline-performance
        - workspace-isolation
        - artifact-management
lastmod: 2025-11-16T14:22:12.480Z
permalink: /posts/work-directory-ci-cd-integration/
attachments: ""
comments: true
difficulty: üü° Intermediate
estimated_reading_time: 25-35 minutes
prerequisites:
    - Understanding of CI/CD concepts and pipelines
    - Experience with GitHub Actions, GitLab CI, or similar platforms
    - Familiarity with build tools (npm, Maven, pip, etc.)
    - Basic knowledge of caching strategies
learning_outcomes:
    - üéØ Design isolated, ephemeral workspaces for CI/CD pipelines
    - ‚ö° Implement selective caching strategies for optimal build speed
    - üõ†Ô∏è Configure work/ directories across major CI/CD platforms
    - üîó Establish guardrails to prevent state leakage and disk exhaustion
    - üìä Measure and optimize pipeline performance using work/ patterns
content_series: DevOps Foundations
related_posts:
    - /posts/working-directories-in-software-development/
validation_methods:
    - Refactor an existing CI/CD pipeline to use the work/ directory pattern
    - Measure build time improvements before and after implementing caching
    - Verify reproducibility by running the same job multiple times
    - Test cache invalidation and restoration scenarios
---

## Introduction

CI/CD pipelines are the assembly lines of modern software development. But unlike factory floors, these assembly lines often carry invisible baggage: leftover artifacts, polluted caches, and mysterious state that makes builds flaky and slow.

The **`work/` directory pattern** solves this by establishing a structured, performance-optimized workspace that treats your CI/CD pipeline like a high-speed conveyor belt:

1. **Feed it raw materials** from your source repository
2. **Cache reusable tools** to avoid redundant downloads
3. **Produce build artifacts** in isolated directories
4. **Ship test reports** and deployable packages
5. **Wipe the belt clean** for the next run

This isn't just about organization‚Äîit's about **reproducibility, speed, and safety**. When implemented correctly, the `work/` pattern can reduce build times by 50-80% while eliminating entire classes of "it works on my machine" failures.

### üåü Why This Matters

Modern CI/CD faces three competing pressures:

- **Speed**: Developers expect sub-5-minute feedback cycles
- **Reliability**: Flaky tests and non-deterministic builds destroy confidence
- **Cost**: Cloud CI minutes translate directly to infrastructure expenses

The `work/` directory pattern addresses all three:

- **Speed**: Aggressive caching of dependencies, smart parallelization, and RAM disk mounting
- **Reliability**: Ephemeral workspaces eliminate state carryover between runs
- **Cost**: Faster builds = fewer CI minutes = lower bills

Traditional approaches mix build outputs, caches, and temporary files into unpredictable locations. The `work/` pattern provides a **contract**‚Äîa structured agreement between your build scripts and your CI infrastructure about where things live and what gets preserved.

### üéØ What You'll Learn

By the end of this article, you'll be able to:

- Architect `work/` directory structures that optimize CI/CD performance
- Implement selective caching strategies that maximize speed without compromising reproducibility
- Configure `work/` integration across GitHub Actions, GitLab CI, CircleCI, and Jenkins
- Establish automated guardrails to prevent common pitfalls
- Measure and continuously optimize pipeline performance

### üìã Before We Begin

This article assumes you:

- Have experience with at least one CI/CD platform
- Understand basic caching concepts (cache keys, invalidation, TTL)
- Can read YAML configuration and shell scripts
- Are familiar with build tool concepts (dependency resolution, compilation, artifact generation)

We'll use GitHub Actions for primary examples, but the patterns apply universally across platforms.

## 1. The `work/` Directory Philosophy

### 1.1 Core Principles

The `work/` directory is built on five foundational principles:

| Principle | Meaning | Impact |
|-----------|---------|--------|
| **Ephemeral per Job** | No state carries over between pipeline runs | Reproducible builds, no flakiness from leftover files |
| **Cache Selectively** | Only preserve `work/cache/`, never `work/build/` | Fast dependency restoration without polluting outputs |
| **Mount as Volume** | Keep `work/` outside container layers when possible | Better I/O performance, easier cleanup |
| **Clean on Exit** | Remove disposable directories after each job | Prevent disk exhaustion on shared runners |
| **Never Commit** | `.gitignore` everything under `work/` | Protect repos from accidentally committed binaries |

### 1.2 The Directory Contract

Think of `work/` as a **standardized API** between your build logic and your infrastructure:

```text
work/                     # ‚Üê Root workspace (mounted, never committed)
‚îú‚îÄ‚îÄ cache/                # ‚Üê PERSISTENT: Survives job runs
‚îÇ   ‚îú‚îÄ‚îÄ npm/              # npm/yarn/pnpm caches
‚îÇ   ‚îú‚îÄ‚îÄ pip/              # Python package cache
‚îÇ   ‚îú‚îÄ‚îÄ maven/            # Java .m2 repository
‚îÇ   ‚îú‚îÄ‚îÄ gradle/           # Gradle build cache
‚îÇ   ‚îî‚îÄ‚îÄ docker/           # Docker BuildKit cache
‚îÇ
‚îú‚îÄ‚îÄ build/                # ‚Üê EPHEMERAL: Regenerated every run
‚îÇ   ‚îú‚îÄ‚îÄ classes/          # Compiled binaries
‚îÇ   ‚îú‚îÄ‚îÄ dist/             # Distribution packages
‚îÇ   ‚îî‚îÄ‚îÄ reports/          # Test/coverage reports ‚Üí ARTIFACT
‚îÇ
‚îú‚îÄ‚îÄ runtime/              # ‚Üê JOB-LOCAL: Services for this run only
‚îÇ   ‚îú‚îÄ‚îÄ test-db/          # Temporary PostgreSQL instance
‚îÇ   ‚îî‚îÄ‚îÄ mock-api/         # Local API server for tests
‚îÇ
‚îî‚îÄ‚îÄ temp/                 # ‚Üê DISPOSABLE: Cleaned every run
    ‚îú‚îÄ‚îÄ ci-logs/          # Verbose build logs
    ‚îî‚îÄ‚îÄ scratch/          # Temporary computation files
```

**Key Insight**: The structure tells you the **lifecycle** of each subdirectory:

- `cache/` = preserve across runs (cache key)
- `build/` = regenerate every run (artifact source)
- `runtime/` = scoped to job execution (cleanup on exit)
- `temp/` = fully disposable (aggressive cleanup)

## 2. CI/CD Integration Strategy

### 2.1 GitHub Actions Implementation

Here's a production-ready GitHub Actions workflow using the `work/` pattern:

```yaml
name: Build and Test
on: [push, pull_request]

jobs:
  build:
    runs-on: ubuntu-latest
    
    env:
      WORK_DIR: ${{ github.workspace }}/work
      CACHE_DIR: ${{ github.workspace }}/work/cache
      BUILD_DIR: ${{ github.workspace }}/work/build
      
    steps:
      # 1. Checkout repository
      - uses: actions/checkout@v4
      
      # 2. Initialize work/ structure
      - name: Setup work directory
        run: |
          mkdir -p work/{cache/{npm,pip,maven},build/{dist,reports},runtime,temp}
          echo "Work directory structure:"
          tree -L 2 work/ || ls -R work/
      
      # 3. Restore dependency cache (only work/cache/)
      - name: Restore dependency cache
        uses: actions/cache@v4
        with:
          path: work/cache/**
          key: ${{ runner.os }}-deps-${{ hashFiles('**/package-lock.json', '**/requirements.txt', '**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-deps-
      
      # 4. Install dependencies (cached)
      - name: Install dependencies
        run: |
          npm install --cache $CACHE_DIR/npm --prefer-offline
          pip install -r requirements.txt --cache-dir $CACHE_DIR/pip
      
      # 5. Build ‚Üí work/build/
      - name: Build application
        run: |
          npm run build -- --output-path=$BUILD_DIR/dist
          echo "Build artifacts:"
          du -sh $BUILD_DIR/dist
      
      # 6. Run tests ‚Üí work/build/reports/
      - name: Run tests
        run: |
          pytest \
            --cache-dir=$CACHE_DIR/pytest \
            --junitxml=$BUILD_DIR/reports/junit.xml \
            --cov --cov-report=xml:$BUILD_DIR/reports/coverage.xml
      
      # 7. Upload test reports as artifacts
      - name: Upload test reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-reports
          path: work/build/reports/
          retention-days: 7
      
      # 8. Upload build artifacts (for deployment)
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: work/build/dist/
          retention-days: 30
      
      # 9. Cleanup disposable directories
      - name: Cleanup
        if: always()
        run: |
          rm -rf work/temp work/runtime work/build
          echo "Remaining work/ size:"
          du -sh work/ || echo "work/ cleaned"
```

**Why This Works**:

- **Lines 7-9**: Environment variables make paths configurable and self-documenting
- **Lines 17-18**: Explicit directory creation prevents "directory not found" errors
- **Lines 21-26**: Only `work/cache/` is cached; build outputs regenerate fresh each time
- **Lines 51-57**: Test reports uploaded as artifacts for debugging, not cached
- **Lines 67-71**: Aggressive cleanup prevents disk exhaustion on shared runners

### 2.2 GitLab CI Implementation

GitLab CI uses a different syntax but the same principles:

```yaml
# .gitlab-ci.yml
variables:
  WORK_DIR: "${CI_PROJECT_DIR}/work"
  CACHE_DIR: "${CI_PROJECT_DIR}/work/cache"
  BUILD_DIR: "${CI_PROJECT_DIR}/work/build"

cache:
  key:
    files:
      - package-lock.json
      - requirements.txt
  paths:
    - work/cache/

stages:
  - setup
  - build
  - test

before_script:
  - mkdir -p work/{cache/{npm,pip},build/{dist,reports},runtime,temp}

setup:
  stage: setup
  script:
    - npm install --cache $CACHE_DIR/npm --prefer-offline
    - pip install -r requirements.txt --cache-dir $CACHE_DIR/pip

build:
  stage: build
  script:
    - npm run build -- --output-path=$BUILD_DIR/dist
  artifacts:
    paths:
      - work/build/dist/
    expire_in: 30 days

test:
  stage: test
  script:
    - pytest --cache-dir=$CACHE_DIR/pytest --junitxml=$BUILD_DIR/reports/junit.xml
  artifacts:
    reports:
      junit: work/build/reports/junit.xml
    paths:
      - work/build/reports/
    expire_in: 7 days

after_script:
  - rm -rf work/{temp,runtime,build}
```

### 2.3 CircleCI Implementation

CircleCI's orb-based approach:

```yaml
version: 2.1

orbs:
  node: circleci/node@5.0

jobs:
  build-and-test:
    docker:
      - image: cimg/node:18.0
    
    environment:
      WORK_DIR: ~/work
      CACHE_DIR: ~/work/cache
      BUILD_DIR: ~/work/build
    
    steps:
      - checkout
      
      - run:
          name: Setup work directory
          command: mkdir -p work/{cache/npm,build/{dist,reports},temp}
      
      - restore_cache:
          keys:
            - v1-deps-{{ checksum "package-lock.json" }}
            - v1-deps-
      
      - run:
          name: Install dependencies
          command: npm install --cache $CACHE_DIR/npm
      
      - save_cache:
          key: v1-deps-{{ checksum "package-lock.json" }}
          paths:
            - work/cache/npm
      
      - run:
          name: Build
          command: npm run build -- --output-path=$BUILD_DIR/dist
      
      - run:
          name: Test
          command: npm test -- --outputFile=$BUILD_DIR/reports/junit.xml
      
      - store_test_results:
          path: work/build/reports/
      
      - store_artifacts:
          path: work/build/dist/

workflows:
  build-test-deploy:
    jobs:
      - build-and-test
```

## 3. Caching Strategy: What to Cache, What to Regenerate

The golden rule: **Cache inputs, not outputs**.

### 3.1 Caching Decision Matrix

| Directory | Cache? | Cache Key Strategy | TTL | Reasoning |
|-----------|--------|-------------------|-----|-----------|
| `work/cache/npm/` | ‚úÖ Yes | `hash(package-lock.json)` | 7 days | Dependencies rarely change; downloading is slow |
| `work/cache/pip/` | ‚úÖ Yes | `hash(requirements.txt)` | 7 days | PyPI downloads can be expensive |
| `work/cache/maven/` | ‚úÖ Yes | `hash(pom.xml)` | 14 days | Maven central is sometimes slow |
| `work/cache/gradle/` | ‚úÖ Yes | `hash(**/*.gradle, gradle.properties)` | 7 days | Gradle daemon and dependency cache |
| `work/cache/docker/` | ‚úÖ Yes | `hash(Dockerfile, docker-compose.yml)` | 3 days | BuildKit layer cache |
| `work/build/dist/` | ‚ùå No | N/A | N/A | Outputs must be reproducible from source |
| `work/build/reports/` | ‚ùå No | N/A | N/A | Test results should reflect current code |
| `work/runtime/` | ‚ùå No | N/A | N/A | Job-local services, not persistent |
| `work/temp/` | ‚ùå No | N/A | N/A | Fully disposable scratch space |

### 3.2 Advanced Caching Patterns

#### Multi-Layer Cache Keys

Use fallback keys for partial cache hits:

```yaml
- uses: actions/cache@v4
  with:
    path: work/cache/**
    key: ${{ runner.os }}-${{ matrix.node-version }}-${{ hashFiles('**/package-lock.json') }}
    restore-keys: |
      ${{ runner.os }}-${{ matrix.node-version }}-
      ${{ runner.os }}-
```

**Why**: If `package-lock.json` changes, you still get the OS-level cache (better than nothing).

#### Partitioned Caches by Language/Tool

```yaml
- name: Cache Node.js dependencies
  uses: actions/cache@v4
  with:
    path: work/cache/npm
    key: npm-${{ hashFiles('package-lock.json') }}

- name: Cache Python dependencies
  uses: actions/cache@v4
  with:
    path: work/cache/pip
    key: pip-${{ hashFiles('requirements.txt') }}
```

**Why**: Independent invalidation‚Äîchanging Python deps doesn't bust your npm cache.

#### BuildKit Docker Layer Caching

```bash
# In Dockerfile
# syntax=docker/dockerfile:1.4

FROM node:18 AS builder

# Mount cache during build
RUN --mount=type=cache,target=/root/.npm \
    npm install --prefer-offline

# Output goes to work/build/dist (not cached)
COPY . /app
RUN npm run build -- --output-path=/app/work/build/dist
```

Then in CI:

```yaml
- name: Build Docker image with cache
  run: |
    docker buildx build \
      --cache-from type=local,src=work/cache/docker \
      --cache-to type=local,dest=work/cache/docker \
      -t myapp:latest .
```

## 4. Performance Optimization Techniques

### 4.1 RAM Disk Mounting (3-5√ó Faster Builds)

On Linux/macOS, mount `work/` as a tmpfs (RAM disk):

```yaml
- name: Mount work/ as tmpfs
  run: |
    sudo mkdir -p /mnt/ramdisk
    sudo mount -t tmpfs -o size=4G tmpfs /mnt/ramdisk
    ln -s /mnt/ramdisk work
```

**Impact**: Compilation-heavy builds (C++, Rust, large TypeScript) see 3-5√ó speedups because disk I/O is eliminated.

**Caveat**: You lose everything if the job crashes‚Äîensure critical artifacts are copied out before job end.

### 4.2 Parallel Builds in Partitions

Split large projects into parallel build partitions:

```yaml
- name: Parallel build
  run: |
    mkdir -p work/build/partitions/{frontend,backend,api}
    
    npm run build:frontend -- --output-path=work/build/partitions/frontend &
    npm run build:backend -- --output-path=work/build/partitions/backend &
    npm run build:api -- --output-path=work/build/partitions/api &
    
    wait
    
    # Merge artifacts
    cp -r work/build/partitions/* work/build/dist/
```

### 4.3 Pre-Warming Caches in Setup Jobs

For monorepos or multi-stage pipelines:

```yaml
jobs:
  setup-cache:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Pre-install dependencies
        run: npm install --cache work/cache/npm
      - uses: actions/cache/save@v4
        with:
          path: work/cache/npm
          key: npm-${{ hashFiles('package-lock.json') }}
  
  build:
    needs: setup-cache
    runs-on: ubuntu-latest
    steps:
      - uses: actions/cache/restore@v4
        # ... rest of build
```

**Why**: The `build` job starts with a warm cache, skipping slow network calls.

## 5. Guardrails and Validation

### 5.1 Enforce `.gitignore` Rules

Prevent accidental commits of `work/` contents:

```yaml
# .github/workflows/validate-work.yml
name: Validate work/ Directory

on: [push, pull_request]

jobs:
  check-gitignore:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Verify work/ is gitignored
        run: |
          if ! grep -q "^work/$" .gitignore; then
            echo "ERROR: work/ must be in .gitignore"
            exit 1
          fi
      
      - name: Fail if work/ in commit
        run: |
          if git diff --cached --name-only | grep -q "^work/"; then
            echo "ERROR: work/ files should not be committed"
            exit 1
          fi
```

### 5.2 Disk Space Monitoring

Prevent disk exhaustion:

```yaml
- name: Monitor disk usage
  if: always()
  run: |
    df -h
    du -sh work/ || echo "work/ already cleaned"
    
    # Auto-cleanup old caches if disk > 90% full
    if [ $(df / | tail -1 | awk '{print $5}' | sed 's/%//') -gt 90 ]; then
      echo "Disk usage > 90%, cleaning old caches..."
      find work/cache -type f -mtime +7 -delete
    fi
```

### 5.3 Cache Invalidation Tests

Ensure your cache strategy works:

```yaml
- name: Test cache invalidation
  run: |
    # Bust the cache by modifying package-lock.json
    echo "# cache-buster" >> package-lock.json
    
    # Verify cache miss on next run
    npm install --cache work/cache/npm --verbose | tee install.log
    
    if grep -q "cache hit" install.log; then
      echo "ERROR: Cache should have been invalidated"
      exit 1
    fi
```

## 6. Automation Rules for AI Agents

If you're building AI-powered CI/CD orchestration, encode these rules:

| Trigger Event | AI Agent Action |
|---------------|-----------------|
| **Pipeline start** | `mkdir -p work/{cache,build,runtime,temp}` |
| **Dependency install** | Use `--cache-dir=work/cache/<tool>` |
| **Build step** | Output to `work/build/dist` |
| **Test execution** | Write reports to `work/build/reports` |
| **Artifact upload** | Source from `work/build/reports/**` or `work/build/dist` |
| **Job end** | `rm -rf work/{temp,runtime,build}` |
| **Disk usage > 90%** | `find work/cache -type f -mtime +7 -delete` |
| **Cache miss** | Log warning, proceed with fresh install |
| **Build failure** | Preserve `work/build/reports` for debugging |

### Example: AI-Powered Cache Strategy Optimization

```python
# Pseudo-code for AI agent
def optimize_cache_strategy(pipeline_history):
    for job in pipeline_history:
        if job.cache_restore_time > 60:  # seconds
            suggest_partition_cache_by_language(job)
        
        if job.cache_hit_rate < 0.5:
            suggest_refine_cache_key(job)
        
        if job.build_time > job.cache_restore_time * 5:
            suggest_ram_disk_mount(job)
```

## 7. Measuring Success: Metrics to Track

### 7.1 Key Performance Indicators

| Metric | Measurement | Target |
|--------|-------------|--------|
| **Total build time** | Job duration (start to finish) | < 5 minutes |
| **Cache hit rate** | (cache hits / total builds) √ó 100 | > 80% |
| **Cache restore time** | Time to restore `work/cache/` | < 30 seconds |
| **Artifact size** | Size of uploaded `work/build/` artifacts | < 500 MB |
| **Disk usage peak** | Max `work/` size during job | < 4 GB |
| **Build reproducibility** | % of builds passing after cache bust | > 95% |

### 7.2 Benchmark Script

```bash
#!/usr/bin/env bash
# benchmark-work-pattern.sh

set -euo pipefail

echo "=== Benchmarking work/ Pattern ==="

# 1. Measure cold build (no cache)
rm -rf work/cache
time npm install --cache work/cache/npm > /dev/null 2>&1
COLD_BUILD=$?

# 2. Measure warm build (with cache)
time npm install --cache work/cache/npm --prefer-offline > /dev/null 2>&1
WARM_BUILD=$?

# 3. Measure cache size
CACHE_SIZE=$(du -sh work/cache | cut -f1)

# 4. Measure build output size
npm run build -- --output-path=work/build/dist
BUILD_SIZE=$(du -sh work/build/dist | cut -f1)

echo "Results:"
echo "  Cold build: ${COLD_BUILD}s"
echo "  Warm build: ${WARM_BUILD}s"
echo "  Cache size: ${CACHE_SIZE}"
echo "  Build output: ${BUILD_SIZE}"
echo "  Speedup: $(echo "scale=2; $COLD_BUILD / $WARM_BUILD" | bc)x"
```

Run this before and after implementing the `work/` pattern to quantify improvements.

## 8. Multi-Platform Examples

### 8.1 Jenkins Pipeline

```groovy
pipeline {
    agent any
    
    environment {
        WORK_DIR = "${WORKSPACE}/work"
        CACHE_DIR = "${WORKSPACE}/work/cache"
        BUILD_DIR = "${WORKSPACE}/work/build"
    }
    
    stages {
        stage('Setup') {
            steps {
                sh 'mkdir -p work/{cache/npm,build/dist,temp}'
            }
        }
        
        stage('Restore Cache') {
            steps {
                // Jenkins uses stash/unstash
                unstash 'npm-cache'
            }
        }
        
        stage('Build') {
            steps {
                sh 'npm install --cache $CACHE_DIR/npm'
                sh 'npm run build -- --output-path=$BUILD_DIR/dist'
            }
        }
        
        stage('Test') {
            steps {
                sh 'npm test -- --outputFile=$BUILD_DIR/reports/junit.xml'
            }
        }
        
        stage('Archive') {
            steps {
                archiveArtifacts artifacts: 'work/build/dist/**', fingerprint: true
                junit 'work/build/reports/junit.xml'
            }
        }
        
        stage('Save Cache') {
            steps {
                stash name: 'npm-cache', includes: 'work/cache/npm/**'
            }
        }
    }
    
    post {
        always {
            sh 'rm -rf work/{temp,runtime,build}'
        }
    }
}
```

### 8.2 Azure Pipelines

```yaml
# azure-pipelines.yml
trigger:
  - main

pool:
  vmImage: 'ubuntu-latest'

variables:
  WORK_DIR: '$(Pipeline.Workspace)/work'
  CACHE_DIR: '$(Pipeline.Workspace)/work/cache'
  BUILD_DIR: '$(Pipeline.Workspace)/work/build'

steps:
- checkout: self

- task: Cache@2
  inputs:
    key: 'npm | "$(Agent.OS)" | package-lock.json'
    path: $(CACHE_DIR)/npm
    restoreKeys: |
      npm | "$(Agent.OS)"

- script: |
    mkdir -p work/{cache/npm,build/dist,temp}
  displayName: 'Setup work directory'

- script: |
    npm install --cache $(CACHE_DIR)/npm
  displayName: 'Install dependencies'

- script: |
    npm run build -- --output-path=$(BUILD_DIR)/dist
  displayName: 'Build application'

- script: |
    npm test -- --outputFile=$(BUILD_DIR)/reports/junit.xml
  displayName: 'Run tests'

- task: PublishTestResults@2
  inputs:
    testResultsFiles: '$(BUILD_DIR)/reports/junit.xml'

- task: PublishBuildArtifacts@1
  inputs:
    pathToPublish: '$(BUILD_DIR)/dist'
    artifactName: 'dist'

- script: |
    rm -rf work/{temp,runtime,build}
  displayName: 'Cleanup'
  condition: always()
```

## 9. Advanced Patterns

### 9.1 Containerized Builds with work/ Mounting

```yaml
# docker-compose.ci.yml
version: '3.8'

services:
  builder:
    image: node:18
    volumes:
      - ./:/app
      - ./work/cache/npm:/root/.npm:cached
      - ./work/build:/app/build
    working_dir: /app
    command: npm run build -- --output-path=/app/build/dist
```

Then in CI:

```yaml
- name: Build in container
  run: docker-compose -f docker-compose.ci.yml up --abort-on-container-exit
```

**Why**: Isolates build environment while preserving cache between runs.

### 9.2 Multi-Stage Builds with Shared Cache

```dockerfile
# syntax=docker/dockerfile:1.4

FROM node:18 AS builder

WORKDIR /app

# Mount cache during dependency install
RUN --mount=type=bind,source=package.json,target=package.json \
    --mount=type=bind,source=package-lock.json,target=package-lock.json \
    --mount=type=cache,target=/root/.npm \
    npm ci --prefer-offline

# Copy source and build
COPY . .
RUN npm run build -- --output-path=/app/work/build/dist

# Production stage (no cache, minimal size)
FROM node:18-alpine
WORKDIR /app
COPY --from=builder /app/work/build/dist ./dist
CMD ["node", "dist/server.js"]
```

## ‚úÖ Validation and Practice

### Exercise 1: Refactor a Pipeline to Use work/

1. Choose an existing CI/CD pipeline
2. Identify where dependencies are installed and where build outputs go
3. Refactor to use the `work/` structure:
   - Dependencies ‚Üí `work/cache/`
   - Build outputs ‚Üí `work/build/`
   - Test reports ‚Üí `work/build/reports/`
4. Measure build time before and after
5. Test cache invalidation by modifying a lock file

**Success Criteria**:
- [ ] Build time reduced by >30% on cached runs
- [ ] No build outputs committed to git
- [ ] Cache hit rate >80% over 10 runs

### Exercise 2: Implement Guardrails

1. Add a `.gitignore` validation workflow
2. Implement disk usage monitoring
3. Add cache invalidation tests
4. Set up build time alerting (if build > 10 minutes)

**Success Criteria**:
- [ ] Attempting to commit `work/` fails in pre-commit hook
- [ ] Disk usage warnings appear when >85% full
- [ ] Cache busting is detected and logged

### Exercise 3: Optimize for Speed

1. Benchmark your current pipeline
2. Implement one optimization:
   - RAM disk mounting
   - Partitioned caches
   - Parallel build stages
3. Re-benchmark and compare

**Success Criteria**:
- [ ] Documented before/after metrics
- [ ] >50% speedup on at least one stage
- [ ] Reproducibility maintained (same outputs)

## üîß Troubleshooting Guide

### Common Issues and Solutions

#### Issue 1: Cache Restored But Build Still Slow
**Symptoms**: Cache shows as "restored" but dependencies still download
**Causes**: Cache key collision, cache corruption, or wrong cache path
**Solution**:
```yaml
# Add debug logging
- name: Debug cache
  run: |
    echo "Cache should be at: $CACHE_DIR/npm"
    ls -lah $CACHE_DIR/npm || echo "Cache empty!"
    npm config get cache
```
**Prevention**: Use specific cache keys, validate cache after restore

#### Issue 2: Disk Space Exhausted
**Symptoms**: "No space left on device" errors
**Causes**: Large caches, accumulating `work/` directories, Docker layer bloat
**Solution**:
```bash
# Emergency cleanup
find work/ -type f -mtime +1 -delete  # Delete files >1 day old
docker system prune -af               # Clean Docker
df -h                                 # Verify space freed
```
**Prevention**: Add disk monitoring, set TTLs on caches, use cleanup jobs

#### Issue 3: Flaky Builds After work/ Migration
**Symptoms**: Tests pass locally, fail in CI, or vice versa
**Causes**: Incorrect paths, missing environment variables, cache pollution
**Diagnosis**:
```bash
# Compare environments
echo "=== Local ==="
pwd
echo $WORK_DIR
ls -R work/

echo "=== CI ==="
# (copy output from CI logs)
```
**Resolution**: Make all paths absolute, use environment variables consistently

## üöÄ Next Steps and Further Learning

### üîÆ Advanced Topics to Explore

- **Distributed Caching**: Share caches across teams using centralized storage (S3, Azure Blob)
- **Incremental Builds**: Only rebuild changed modules (Nx, Turborepo, Bazel)
- **Remote Execution**: Run builds on dedicated clusters (BuildBuddy, Earthly)
- **Reproducible Builds**: Achieve bit-for-bit identical outputs across environments

### üìö Recommended Learning Path

- **Foundation Building**: Master your CI/CD platform's caching mechanisms
- **Skill Expansion**: Learn Docker BuildKit, multi-stage builds, and layer optimization
- **Specialization Options**: Explore Bazel, Nix, or Pants for hermetic builds

### üåê Community and Resources

- [GitHub Actions Cache Documentation](https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows)
- [GitLab CI/CD Cache Best Practices](https://docs.gitlab.com/ee/ci/caching/)
- [Docker BuildKit Cache Mounts](https://docs.docker.com/build/cache/)
- [Reproducible Builds Project](https://reproducible-builds.org/)

### üéØ Project Ideas

- **Beginner Project**: Refactor a simple Node.js project to use `work/`
- **Intermediate Project**: Implement cross-platform caching for a monorepo
- **Advanced Project**: Build a self-optimizing CI pipeline that adjusts cache strategies based on historical data

## üìö Resources and References

### üìñ Essential Documentation
- [GitHub Actions: Caching Dependencies](https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows)
- [GitLab CI: Cache](https://docs.gitlab.com/ee/ci/caching/)
- [CircleCI: Caching Strategies](https://circleci.com/docs/caching/)
- [Docker BuildKit Cache Mounts](https://docs.docker.com/build/building/cache/)

### üé• Video and Interactive Resources
- [GitHub Actions: Optimizing Workflows](https://www.youtube.com/results?search_query=github+actions+caching)
- [DevOps CI/CD Best Practices](https://www.youtube.com/results?search_query=cicd+best+practices)

### üí¨ Community Support
- [Stack Overflow: CI/CD](https://stackoverflow.com/questions/tagged/continuous-integration)
- [r/devops](https://reddit.com/r/devops) - CI/CD discussions and troubleshooting
- [DevOps Discord Communities](https://discord.gg/devops)

### üîß Tools and Utilities
- [actions/cache](https://github.com/actions/cache) - GitHub Actions caching action
- [cache-buildkit](https://github.com/moby/buildkit) - Docker BuildKit with advanced caching
- [turbo](https://turbo.build/) - High-performance build system with intelligent caching

### üìÑ Templates and Examples
- [GitHub Actions Examples](https://github.com/actions/starter-workflows)
- [GitLab CI Templates](https://gitlab.com/gitlab-org/gitlab/-/tree/master/lib/gitlab/ci/templates)
- [CircleCI Orbs](https://circleci.com/developer/orbs)

---

## Final Thoughts

The `work/` directory pattern transforms CI/CD from a source of frustration into a competitive advantage. By treating your pipeline as a **structured, stateful-but-disposable conveyor belt**, you gain:

- **Predictability**: Same inputs ‚Üí same outputs, every time
- **Speed**: Aggressive caching without fragility
- **Safety**: No state leakage, no mysterious failures
- **Observability**: Clear structure makes debugging straightforward

Start small:

1. Create the directory structure
2. Move one build output to `work/build/`
3. Cache one dependency directory in `work/cache/`
4. Measure the improvement
5. Iterate and expand

Within a few sprints, you'll wonder how you ever shipped software without it.

---

*Last Updated: November 16, 2025 ‚Äî IT-Journey Team*
